## Reference
https://debezium.io/documentation/reference/stable/tutorial.html

## Create a network

```
docker network create kafka-net
```

## Start Zookeeper

```
docker run -it --rm --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 --network kafka-net debezium/zookeeper:2.7
```

## Start Kafka

```
docker run -it --rm --name kafka -p 9092:9092 --network kafka-net -e ZOOKEEPER_CONNECT=zookeeper:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://host.docker.internal:9092 debezium/kafka:2.7
```

## Start MySQL

```
docker run -it --rm --name mysql -p 3306:3306 --network kafka-net -e MYSQL_ROOT_PASSWORD=debezium -e MYSQL_USER=mysqluser -e MYSQL_PASSWORD=mysqlpw debezium/example-mysql:2.7
```

## Start MySQL Client

```
docker run -it --rm --name mysqlterm --network kafka-net --link mysql mysql:8.2 sh -c 'exec mysql -h"$MYSQL_PORT_3306_TCP_ADDR" -P"$MYSQL_PORT_3306_TCP_PORT" -uroot -p"$MYSQL_ENV_MYSQL_ROOT_PASSWORD"'
docker network connect kafka-net mysqlterm
```

Alternatively,
```
apt-get install mysql-client
mysql -h0.0.0.0 -uroot -pdebezium
```

## Start Kafka Connect

```
docker run -it --rm --name connect -p 8083:8083 --network kafka-net -e GROUP_ID=1 -e CONFIG_STORAGE_TOPIC=my_connect_configs -e OFFSET_STORAGE_TOPIC=my_connect_offsets -e STATUS_STORAGE_TOPIC=my_connect_statuses -e BOOTSTRAP_SERVERS=kafka:9092 debezium/connect:2.7
```


## Register the Debezium MySQL Connector

```
{
  "name": "inventory-connector",  
  "config": {  
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",  
    "database.hostname": "mysql",  
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "184054",  
    "topic.prefix": "dbserver1",  
    "database.include.list": "inventory",  
    "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",  
    "schema.history.internal.kafka.topic": "schema-changes.inventory"  
  }
}
```

```
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{ "name": "inventory-connector", "config": { "connector.class": "io.debezium.connector.mysql.MySqlConnector", "tasks.max": "1", "database.hostname": "mysql", "database.port": "3306", "database.user": "debezium", "database.password": "dbz", "database.server.id": "184054", "topic.prefix": "dbserver1", "database.include.list": "inventory", "schema.history.internal.kafka.bootstrap.servers": "kafka:9092", "schema.history.internal.kafka.topic": "schemahistory.inventory" } }'
```

## Viewing Change events

```
docker run -it --rm --name watcher --network kafka-net -e ZOOKEEPER_CONNECT=zookeeper:2181 -e KAFKA_BROKER=kafka:9092 debezium/kafka:2.7 watch-topic -a -k dbserver1.inventory.customers
```

## Install RedPanda UI

```
docker run -p 8080:8080 -e KAFKA_BROKERS=host.docker.internal:9092 docker.redpanda.com/redpandadata/console:latest
open http://localhost:8080
```


### Log Compaction, Tombstone events

If Kafka is set up to be log compacted, it will remove older messages from the topic if there is at least one message later in the topic with same key. This last event is called a tombstone event, because it has a key and an empty value. This means that Kafka will remove all prior messages with the same key. Even though the prior messages will be removed, the tombstone event means that consumers can still read the topic from the beginning and not miss any events.

## TODO

Try running this with `Docker Compose` and then on `K8S`
Try running with different source connectors